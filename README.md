# 大众点评评论的4分类20个多任务学习

## 0 写在前
>> 多任务学习是继深度学习能够解决单个分类或回归问题之后的一个重要研究方向，它提出的主要背景是，算法工程师总能希望进行一次训练，可以将多个相关的任务目标或不那么相关的目标进行统一的学习，想法很容易理解，这样Multi Task Learing既可以找到同一个对象的多个任务（诸如一个人的身高、体重、年龄、收入等多个目标的预测）相关联系，以便于更好得获得高层语义理解（如任务画像的多个标签），同时还可以并行学习，节约大量的时间。MTL正是在这样的背景之下提出，但是想法遭遇了现实问题的抵抗，容易想到的是，每个任务的loss function评价体系不一样怎么处理、在训练过程中，每个Task的权重怎么进行有效学习，复杂的任务如何避免遭受一些简单学习任务的影响（换句话说，复杂任务的loss死活下降不下去，而简单任务的准确度accuracy却已接近于、假使你也已经训练出来了，那么如何评价这个MTL模型的好坏也是一个要研究的问题。  
>> 幸好，前人已经做了大量的基础研究工作。针对MTL，我们能够找到大体三种学习方法：  
>>> * （1）基于特征分享的多任务学习方法；  
>>> * （2）基于模型参数分享的多任务学习方法；  
>>> * （3）基于深度学习的多任务学习方法。  
&nbsp; &nbsp; 对于前两种方法，大多是SVM等机器学习的方法，不再赘述，详情可参考[中科大博士的一篇论文]()进行查找。本文基于深度学习的多任务学习方法，讲2种方法，一种是手动调参（loss_weight），任务学习个数不受限制，第二种方法则是重构loss_function，将同方差Uncertainty（可以理解为求使多个任务loss的乘积最小值的一组loss_weight参数求解），对于回归和分类2个任务学习的代码也展示在[这里]()。  

